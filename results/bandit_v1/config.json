{
  "algo": "PPO",
  "env_name": "MultiArmedBandit-v0",
  "env_configs": {
    "num_actions": 10
  },
  "num_env_steps": 500000,
  "actor_lr": 0.001,
  "critic_lr": 0.001,
  "optimizer_eps": 1e-05,
  "max_grad_norm": 0.5,
  "use_linear_lr_decay": false,
  "random_seed": 1,
  "cuda_deterministic": false,
  "use_cuda": true,
  "steps_per_rollout": 1000,
  "num_processes": 16,
  "discount_gamma": 0.99,
  "use_proper_time_limits": false,
  "ppo_num_epochs": 4,
  "ppo_clip_param": 0.2,
  "ppo_entropy_coef": 0.01,
  "ppo_value_loss_coef": 0.5,
  "ppo_num_minibatches": 4,
  "use_gae": true,
  "gae_lambda": 0.95,
  "directory": "./results/bandit_v1/",
  "log_interval": 1,
  "checkpoint_interval": 1,
  "eval_interval": 1
}