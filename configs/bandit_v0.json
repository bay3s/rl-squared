{
  "algo": "PPO",
  "env_name": "Bandit-v0",
  "env_configs": {
    "num_actions": 3
  },
  "num_env_steps": 2000000,
  "actor_lr": 0.0001,
  "critic_lr": 0.0001,
  "optimizer_eps": 0.00001,
  "max_grad_norm": 0.5,
  "use_linear_lr_decay": false,
  "random_seed": 4536,
  "cuda_deterministic": false,
  "use_cuda": true,
  "steps_per_trial": 250,
  "num_processes": 10,
  "discount_gamma": 0.99,
  "use_proper_time_limits": false,
  "ppo_num_epochs": 4,
  "ppo_num_minibatches": 4,
  "ppo_clip_param": 0.1,
  "ppo_entropy_coef": 0.01,
  "ppo_value_loss_coef": 0.5,
  "use_gae": true,
  "gae_lambda": 0.3,
  "directory": "./results/bandit_v0/",
  "log_interval": 1,
  "checkpoint_interval": 1,
  "eval_interval": 1
}
