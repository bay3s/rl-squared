{
  "algo": "PPO",
  "env_name": "TabularMDP-v1",
  "env_configs": {
    "num_states": 10,
    "num_actions": 5,
    "episode_length": 10
  },
  "actor_lr": 0.0001,
  "critic_lr": 0.0003,
  "use_linear_lr_decay": false,
  "optimizer_eps": 0.00001,
  "max_grad_norm": 0.5,
  "random_seed": 796,
  "cuda_deterministic": false,
  "use_cuda": true,
  "policy_iterations": 250,
  "meta_episode_length": 1000,
  "meta_episodes_per_epoch": 250,
  "num_processes": 20,
  "discount_gamma": 0.99,
  "ppo_opt_epochs": 10,
  "ppo_num_minibatches": 50,
  "ppo_clip_param": 0.1,
  "ppo_entropy_coef": 0.01,
  "ppo_value_loss_coef": 0.5,
  "use_gae": true,
  "gae_lambda": 0.3
}
